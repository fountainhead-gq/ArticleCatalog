在学习python爬虫的过程中，总会遇到要获取网页内容的时候，下面就对如何获取网页内容进行总结。

方法一：
```
import urllib.request

url = "xxxx"
#模拟浏览器访问
headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko'
}
# req = urllib.request.Request(hostname, headers=headers)
req = urllib.request.Request(url)
req.add_header("User-Agent", "fake-client")
web_page = urllib.request.urlopen(req)
data = web_page.read().decode('utf-8')

print(data)
```

方法二：
```
import urllib.request
from bs4 import BeautifulSoup #这里需要导入BeautifulSoup

url='http://www.baidu.com'
headers = ('User-Agent', 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.154 Safari/537.36')
handler = urllib.request.ProxyHandler({'http': 'http://www.baidu.com/'})
opener = urllib.request.build_opener(handler)
urllib.request.install_opener(opener)
opener.add_handler = headers
# content = opener.open(url).read().decode('gbk', 'ignore').encode('utf-8')
content = opener.open(url).read()
soup = BeautifulSoup(content, "html5lib")
print(soup)
```

方法三：
```
import requests

url='http://www.baidu.com'
content=requests.get(url).content
print (content)
```
这里是使用的python的requests模块获取网页的内容。


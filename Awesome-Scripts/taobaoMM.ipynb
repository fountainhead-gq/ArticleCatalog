{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3\n",
      "start downloading 田媛媛\n",
      "current page 1\n",
      "start downloading album 10000702574 45 张\n",
      "start downloading album 301381083 91 张\n",
      "start downloading album 10000196901 118 张\n",
      "start downloading album 301563127 15 张\n",
      "start downloading album 10000587450 110 张\n",
      "start downloading album 10000692814 6 张\n",
      "start downloading album 183809402 679 张\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import sys\n",
    "import imghdr\n",
    "PY3 = sys.version.startswith('3')\n",
    "if PY3:\n",
    "    from urllib.request import Request, urlopen\n",
    "    print ('python 3')\n",
    "else:\n",
    "    from urllib2 import Request, urlopen\n",
    "    print ('python 2')\n",
    "\n",
    "class Crawler(object):\n",
    "    def __init__(self):\n",
    "        super(Crawler, self).__init__()\n",
    "        self.album_prefix = 'https://mm.taobao.com/self/album/open_album_list.htm?_charset=utf-8&user_id%20={0}&page={1}'\n",
    "        self.image_prefix = 'https://mm.taobao.com/album/json/get_album_photo_list.htm?user_id={0}&album_id={1}&page={2}'\n",
    "        self.image_pattern = re.compile('''img.*290x10000.jpg''', re.U)\n",
    "        self.image_name_pattern = re.compile('''\"picId\":\"(.*?)\"''', re.U)\n",
    "        self.model_pattern = re.compile('''<a class=\"lady-name\" href=\"(.*?)\".*>(.*?)</a>''', re.U)\n",
    "        self.album_pattern = re.compile('''.*album_id=(.*?)&.*''', re.U)\n",
    "        self.links = []\n",
    "        self.ids= []\n",
    "        self.names= []\n",
    "\n",
    "    def readHtml(self, html):\n",
    "        req = Request(html)\n",
    "        resp = urlopen(req)\n",
    "        content = resp.read()\n",
    "        if PY3:\n",
    "            charset = resp.headers.get_content_charset()\n",
    "        else:\n",
    "            charset = resp.headers.getparam('charset')\n",
    "        if charset:\n",
    "            content = content.decode(charset)\n",
    "        return content\n",
    "\n",
    "    def getLinkIdAndNames(self, htmlData):\n",
    "        items = re.findall(self.model_pattern, htmlData)\n",
    "        self.links = [link for link, name in items]\n",
    "        self.names = [name for link, name in items]\n",
    "        self.ids = [link[link.index('=')+1:] for link in self.links]\n",
    "\n",
    "    def getAlbums(self):\n",
    "        for i, model_id in enumerate(self.ids):\n",
    "            print ('start downloading %s'%self.names[i])\n",
    "            try:\n",
    "                os.mkdir(self.names[i])\n",
    "            except OSError as e:\n",
    "                pass\n",
    "            os.chdir(self.names[i])\n",
    "            for page in range(1, 10):\n",
    "                print ('current page %s'%page)\n",
    "                model_url = self.album_prefix.format(model_id, page)\n",
    "                soup = bs(self.readHtml(model_url), 'html.parser')\n",
    "                albums = soup.find_all('div', class_ = 'mm-photo-cell-middle')\n",
    "                if not albums:\n",
    "                    break\n",
    "                for album in albums:\n",
    "                    album_name = album.find('h4').a.string.strip().rstrip('.')\n",
    "                    album_link= album.find('h4').a['href']\n",
    "                    album_id = re.findall(self.album_pattern, album_link)[0]\n",
    "                    album_create_time = album.find('p', class_ = 'mm-photo-date').string.lstrip(u'创建时间: ')\n",
    "                    album_img_count = album.find('span', class_ = 'mm-pic-number').string.strip('()')\n",
    "                    # print (album_name, album_create_time, album_img_count, album_id)\n",
    "                    subDir = ''.join([album_name, '_', album_create_time, u'共',  album_img_count])\n",
    "                    try:\n",
    "                        os.mkdir(subDir)\n",
    "                    except OSError as e:\n",
    "                        pass\n",
    "                    os.chdir(subDir)\n",
    "                    self.getImages(model_id, album_id, album_img_count.strip(u'张'))\n",
    "                    os.chdir('..')\n",
    "            os.chdir('..')\n",
    "            print ('finish downloading', self.names[i])\n",
    "\n",
    "    def getImages(self, model_id, album_id, image_count):\n",
    "        print ('start downloading album %s %s %s' %(album_id, image_count, u'张'))\n",
    "        for page in range(1, int((int(image_count)-1)/16+2)):\n",
    "            link = self.image_prefix.format(model_id, album_id, page)\n",
    "            body = self.readHtml(link)\n",
    "            images = re.findall(self.image_pattern, body)\n",
    "            # tried to use des as names, however, it duplicates times. So i chose pic ids.\n",
    "            names = re.findall(self.image_name_pattern, body)\n",
    "            for idx, image in enumerate(images):\n",
    "                image = image[:image.find('_290')]\n",
    "                image_content = self.readHtml('http://'+image)\n",
    "                image_type = imghdr.what('guest what type of image it is', image_content) or 'jpg'\n",
    "                with open(names[idx]+'.%s'%image_type, 'wb') as img:\n",
    "                    img.write(image_content)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_html = 'https://mm.taobao.com/json/request_top_list.htm?page={0}'\n",
    "    c = Crawler()\n",
    "    for page in range(1, 5):\n",
    "        data = c.readHtml(test_html.format(page))\n",
    "        c.getLinkIdAndNames(data)\n",
    "        c.getAlbums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
